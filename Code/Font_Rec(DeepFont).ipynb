{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hUkBRdY8ndhZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pylab as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import ImageFilter\n",
    "import cv2\n",
    "import itertools\n",
    "import random\n",
    "import keras\n",
    "import imutils\n",
    "from imutils import paths\n",
    "import os\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import callbacks\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D , UpSampling2D ,Conv2DTranspose\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JHEynQv2ndhn"
   },
   "outputs": [],
   "source": [
    "def pil_image(img_path):\n",
    "    pil_im =PIL.Image.open(img_path).convert('L')\n",
    "    pil_im=pil_im.resize((105,105))\n",
    "    #imshow(np.asarray(pil_im))\n",
    "    return pil_im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1hbTCU2qndht"
   },
   "source": [
    "# Augumentation Steps \n",
    "1) Noise\n",
    "2) Blur\n",
    "3) Perpective Rotation\n",
    "4) Shading\n",
    "5) Variable Character Spacing\n",
    "6) Variable Aspect Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MLCHbBKsndhv"
   },
   "outputs": [],
   "source": [
    "def noise_image(pil_im):\n",
    "    # Adding Noise to image\n",
    "    img_array = np.asarray(pil_im)\n",
    "    mean = 0.0   # some constant\n",
    "    std = 5   # some constant (standard deviation)\n",
    "    noisy_img = img_array + np.random.normal(mean, std, img_array.shape)\n",
    "    noisy_img_clipped = np.clip(noisy_img, 0, 255)\n",
    "    noise_img = PIL.Image.fromarray(np.uint8(noisy_img_clipped)) # output\n",
    "    #imshow((noisy_img_clipped ).astype(np.uint8))\n",
    "    noise_img=noise_img.resize((105,105))\n",
    "    return noise_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TPvDBV5ndh2"
   },
   "outputs": [],
   "source": [
    "def blur_image(pil_im):\n",
    "    #Adding Blur to image \n",
    "    blur_img = pil_im.filter(ImageFilter.GaussianBlur(radius=3)) # ouput\n",
    "    #imshow(blur_img)\n",
    "    blur_img=blur_img.resize((105,105))\n",
    "    return blur_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CIDSvv7Qndh6"
   },
   "outputs": [],
   "source": [
    "def affine_rotation(img):\n",
    "    \n",
    "    #img=cv2.imread(img_path,0)\n",
    "    rows, columns = img.shape\n",
    "\n",
    "    point1 = np.float32([[10, 10], [30, 10], [10, 30]])\n",
    "    point2 = np.float32([[20, 15], [40, 10], [20, 40]])\n",
    "\n",
    "    A = cv2.getAffineTransform(point1, point2)\n",
    "\n",
    "    output = cv2.warpAffine(img, A, (columns, rows))\n",
    "    affine_img = PIL.Image.fromarray(np.uint8(output)) # affine rotated output\n",
    "    #imshow(output)\n",
    "    affine_img=affine_img.resize((105,105))\n",
    "    return affine_img\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VCy6ReUNndh_"
   },
   "outputs": [],
   "source": [
    "def gradient_fill(image):\n",
    "    #image=cv2.imread(img_path,0)\n",
    "    laplacian = cv2.Laplacian(image,cv2.CV_64F)\n",
    "    laplacian = cv2.resize(laplacian, (105, 105))\n",
    "    return laplacian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OBLjVHT9ndiF"
   },
   "source": [
    "## Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6hc1RAaVndiI"
   },
   "outputs": [],
   "source": [
    "data_path = \"font_patch/\"\n",
    "data=[]\n",
    "labels=[]\n",
    "imagePaths = sorted(list(paths.list_images(data_path)))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HYYzr_c1ndiN"
   },
   "outputs": [],
   "source": [
    "def conv_label(label):\n",
    "    if label == 'font_patch/Lato':\n",
    "        return 0\n",
    "    elif label == 'font_patch/Raleway':\n",
    "        return 1\n",
    "    elif label == 'font_patch/Roboto':\n",
    "        return 2\n",
    "    elif label == 'font_patch/Sansation':\n",
    "        return 3\n",
    "    elif label == 'font_patch/Walkway':\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5emmKqjd-3Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blur', 'noise', 'affine', 'gradient']\n"
     ]
    }
   ],
   "source": [
    "augument=[\"blur\",\"noise\",\"affine\",\"gradient\"]\n",
    "a=itertools.combinations(augument, 4)\n",
    "\n",
    "for i in list(a): \n",
    "    print(list(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PIc22kLf4SAP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for imagePath in imagePaths:\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    label = conv_label(label)\n",
    "    pil_img = pil_image(imagePath)\n",
    "    #imshow(pil_img)\n",
    "    \n",
    "    # Adding original image\n",
    "    org_img = img_to_array(pil_img)\n",
    "    #print(org_img.shape)\n",
    "    data.append(org_img)\n",
    "    labels.append(label)\n",
    "    \n",
    "    augument=[\"noise\",\"blur\",\"affine\",\"gradient\"]\n",
    "    for l in range(0,len(augument)):\n",
    "    \n",
    "        a=itertools.combinations(augument, l+1)\n",
    "\n",
    "        for i in list(a): \n",
    "            combinations=list(i)\n",
    "            print(len(combinations))\n",
    "            temp_img = pil_img\n",
    "            for j in combinations:\n",
    "            \n",
    "                if j == 'noise':\n",
    "                    # Adding Noise image\n",
    "                    temp_img = noise_image(temp_img)\n",
    "                    \n",
    "                elif j == 'blur':\n",
    "                    # Adding Blur image\n",
    "                    temp_img = blur_image(temp_img)\n",
    "                    #imshow(blur_img)\n",
    "                    \n",
    "    \n",
    "                elif j == 'affine':\n",
    "                    open_cv_affine = np.array(pil_img)\n",
    "                    # Adding affine rotation image\n",
    "                    temp_img = affine_rotation(open_cv_affine)\n",
    "\n",
    "                elif j == 'gradient':\n",
    "                    open_cv_gradient = np.array(pil_img)\n",
    "                    # Adding gradient image\n",
    "                    temp_img = gradient_fill(open_cv_gradient)\n",
    "  \n",
    "            temp_img = img_to_array(temp_img)\n",
    "            data.append(temp_img)\n",
    "            labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cFpIsgdHndit",
    "outputId": "084a49bf-ee2d-4067-cbde-90d9b42bd8c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "data = np.asarray(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "print(\"Success\")\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "\tlabels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1NQr6OCQ_3qO"
   },
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors\n",
    "trainY = to_categorical(trainY, num_classes=5)\n",
    "testY = to_categorical(testY, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9omeq7fqryGW"
   },
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vWihISP8kHV"
   },
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DpDdwzQguqWR"
   },
   "outputs": [],
   "source": [
    " def create_model():\n",
    "  model=Sequential()\n",
    "\n",
    "  # Cu Layers \n",
    "  model.add(Conv2D(64, kernel_size=(48, 48), activation='relu', input_shape=(105,105,1)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "  model.add(Conv2D(128, kernel_size=(24, 24), activation='relu'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "  model.add(Conv2DTranspose(128, (24,24), strides = (2,2), activation = 'relu', padding='same', kernel_initializer='uniform'))\n",
    "  model.add(UpSampling2D(size=(2, 2)))\n",
    "\n",
    "  model.add(Conv2DTranspose(64, (12,12), strides = (2,2), activation = 'relu', padding='same', kernel_initializer='uniform'))\n",
    "  model.add(UpSampling2D(size=(2, 2)))\n",
    "\n",
    "  #Cs Layers\n",
    "  model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
    "\n",
    "  model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
    "\n",
    "  model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
    "\n",
    "  model.add(Flatten())\n",
    "\n",
    "  model.add(Dense(4096, activation='relu'))\n",
    "\n",
    "  model.add(Dropout(0.5))\n",
    "\n",
    "  model.add(Dense(4096,activation='relu'))\n",
    "\n",
    "  model.add(Dropout(0.5))\n",
    "\n",
    "  model.add(Dense(2383,activation='relu'))\n",
    "\n",
    "  model.add(Dense(5, activation='softmax'))\n",
    " \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LSUkpdoI2J-M",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "model= create_model()\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True, name='SGD')\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IH8DclwlLkOw"
   },
   "outputs": [],
   "source": [
    "early_stopping=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min')\n",
    "\n",
    "filepath=\"top_model.h5\"\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [early_stopping,checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZfjlSwNt73XO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.8792 \n",
      "Epoch 00001: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 567s 57s/step - loss: 0.0336 - accuracy: 0.8792 - val_loss: 0.2232 - val_accuracy: 0.2275\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9067 \n",
      "Epoch 00002: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 576s 58s/step - loss: 0.0290 - accuracy: 0.9067 - val_loss: 0.2426 - val_accuracy: 0.2175\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9150 \n",
      "Epoch 00003: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 574s 57s/step - loss: 0.0246 - accuracy: 0.9150 - val_loss: 0.2350 - val_accuracy: 0.2325\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9250 \n",
      "Epoch 00004: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 562s 56s/step - loss: 0.0210 - accuracy: 0.9250 - val_loss: 0.1958 - val_accuracy: 0.2625\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9425 \n",
      "Epoch 00005: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 575s 57s/step - loss: 0.0185 - accuracy: 0.9425 - val_loss: 0.1796 - val_accuracy: 0.2725\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9483 \n",
      "Epoch 00006: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 564s 56s/step - loss: 0.0165 - accuracy: 0.9483 - val_loss: 0.2364 - val_accuracy: 0.2225\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9592 \n",
      "Epoch 00007: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 554s 55s/step - loss: 0.0130 - accuracy: 0.9592 - val_loss: 0.2723 - val_accuracy: 0.2175\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9567 \n",
      "Epoch 00008: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 554s 55s/step - loss: 0.0124 - accuracy: 0.9567 - val_loss: 0.2503 - val_accuracy: 0.2225\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9542 \n",
      "Epoch 00009: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 554s 55s/step - loss: 0.0146 - accuracy: 0.9542 - val_loss: 0.2243 - val_accuracy: 0.2700\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9583 \n",
      "Epoch 00010: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 555s 56s/step - loss: 0.0134 - accuracy: 0.9583 - val_loss: 0.2080 - val_accuracy: 0.3175\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9700 \n",
      "Epoch 00011: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 553s 55s/step - loss: 0.0104 - accuracy: 0.9700 - val_loss: 0.2852 - val_accuracy: 0.2225\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9817 \n",
      "Epoch 00012: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 553s 55s/step - loss: 0.0068 - accuracy: 0.9817 - val_loss: 0.2755 - val_accuracy: 0.2225\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9850 \n",
      "Epoch 00013: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 552s 55s/step - loss: 0.0050 - accuracy: 0.9850 - val_loss: 0.2494 - val_accuracy: 0.2275\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9908 \n",
      "Epoch 00014: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 554s 55s/step - loss: 0.0034 - accuracy: 0.9908 - val_loss: 0.1575 - val_accuracy: 0.4150\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9925 \n",
      "Epoch 00015: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 554s 55s/step - loss: 0.0026 - accuracy: 0.9925 - val_loss: 0.2161 - val_accuracy: 0.3100\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9933 \n",
      "Epoch 00016: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 553s 55s/step - loss: 0.0023 - accuracy: 0.9933 - val_loss: 0.2735 - val_accuracy: 0.2275\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9967 \n",
      "Epoch 00017: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 557s 56s/step - loss: 0.0013 - accuracy: 0.9967 - val_loss: 0.2420 - val_accuracy: 0.2675\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9975     \n",
      "Epoch 00018: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 553s 55s/step - loss: 0.0012 - accuracy: 0.9975 - val_loss: 0.2370 - val_accuracy: 0.3150\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9950 \n",
      "Epoch 00019: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 553s 55s/step - loss: 0.0018 - accuracy: 0.9950 - val_loss: 0.1970 - val_accuracy: 0.4100\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9958 \n",
      "Epoch 00020: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 564s 57s/step - loss: 0.0018 - accuracy: 0.9958 - val_loss: 0.2020 - val_accuracy: 0.3950\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9958 \n",
      "Epoch 00021: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 553s 55s/step - loss: 0.0013 - accuracy: 0.9958 - val_loss: 0.1807 - val_accuracy: 0.4225\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9975 \n",
      "Epoch 00022: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 552s 55s/step - loss: 0.0010 - accuracy: 0.9975 - val_loss: 0.1478 - val_accuracy: 0.5275\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9967 \n",
      "Epoch 00023: val_loss did not improve from 0.14456\n",
      "10/10 [==============================] - 555s 56s/step - loss: 0.0012 - accuracy: 0.9967 - val_loss: 0.1778 - val_accuracy: 0.4250\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9967     \n",
      "Epoch 00024: val_loss improved from 0.14456 to 0.10037, saving model to top_model.h5\n",
      "10/10 [==============================] - 556s 56s/step - loss: 0.0011 - accuracy: 0.9967 - val_loss: 0.1004 - val_accuracy: 0.6700\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9950 \n",
      "Epoch 00025: val_loss did not improve from 0.10037\n",
      "10/10 [==============================] - 553s 55s/step - loss: 0.0018 - accuracy: 0.9950 - val_loss: 0.1591 - val_accuracy: 0.5025\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9933 \n",
      "Epoch 00026: val_loss did not improve from 0.10037\n",
      "10/10 [==============================] - 553s 55s/step - loss: 0.0018 - accuracy: 0.9933 - val_loss: 0.1956 - val_accuracy: 0.4200\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9958 \n",
      "Epoch 00027: val_loss did not improve from 0.10037\n",
      "10/10 [==============================] - 555s 56s/step - loss: 0.0016 - accuracy: 0.9958 - val_loss: 0.1006 - val_accuracy: 0.6775\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9958 \n",
      "Epoch 00028: val_loss did not improve from 0.10037\n",
      "10/10 [==============================] - 552s 55s/step - loss: 0.0017 - accuracy: 0.9958 - val_loss: 0.1553 - val_accuracy: 0.5250\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9933 \n",
      "Epoch 00029: val_loss improved from 0.10037 to 0.06250, saving model to top_model.h5\n",
      "10/10 [==============================] - 556s 56s/step - loss: 0.0016 - accuracy: 0.9933 - val_loss: 0.0625 - val_accuracy: 0.7875\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9967   \n",
      "Epoch 00030: val_loss improved from 0.06250 to 0.03700, saving model to top_model.h5\n",
      "10/10 [==============================] - 558s 56s/step - loss: 0.0011 - accuracy: 0.9967 - val_loss: 0.0370 - val_accuracy: 0.8825\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 3.6833e-04 - accuracy: 1.0000 \n",
      "Epoch 00031: val_loss improved from 0.03700 to 0.03436, saving model to top_model.h5\n",
      "10/10 [==============================] - 556s 56s/step - loss: 3.6833e-04 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.8800\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 4.8837e-04 - accuracy: 0.9983 \n",
      "Epoch 00032: val_loss did not improve from 0.03436\n",
      "10/10 [==============================] - 561s 56s/step - loss: 4.8837e-04 - accuracy: 0.9983 - val_loss: 0.0346 - val_accuracy: 0.8925\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 1.0033e-04 - accuracy: 1.0000 \n",
      "Epoch 00033: val_loss improved from 0.03436 to 0.03427, saving model to top_model.h5\n",
      "10/10 [==============================] - 558s 56s/step - loss: 1.0033e-04 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 0.8775\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 4.2737e-04 - accuracy: 0.9983 \n",
      "Epoch 00034: val_loss improved from 0.03427 to 0.03069, saving model to top_model.h5\n",
      "10/10 [==============================] - 555s 56s/step - loss: 4.2737e-04 - accuracy: 0.9983 - val_loss: 0.0307 - val_accuracy: 0.8775\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9950 \n",
      "Epoch 00035: val_loss did not improve from 0.03069\n",
      "10/10 [==============================] - 554s 55s/step - loss: 0.0015 - accuracy: 0.9950 - val_loss: 0.0325 - val_accuracy: 0.8825\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 3.1354e-04 - accuracy: 1.0000 \n",
      "Epoch 00036: val_loss improved from 0.03069 to 0.03029, saving model to top_model.h5\n",
      "10/10 [==============================] - 559s 56s/step - loss: 3.1354e-04 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.8950\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9958   \n",
      "Epoch 00037: val_loss did not improve from 0.03029\n",
      "10/10 [==============================] - 554s 55s/step - loss: 0.0011 - accuracy: 0.9958 - val_loss: 0.0312 - val_accuracy: 0.9025\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9950 \n",
      "Epoch 00038: val_loss did not improve from 0.03029\n",
      "10/10 [==============================] - 554s 55s/step - loss: 0.0019 - accuracy: 0.9950 - val_loss: 0.0457 - val_accuracy: 0.8500\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9900 \n",
      "Epoch 00039: val_loss did not improve from 0.03029\n",
      "10/10 [==============================] - 553s 55s/step - loss: 0.0038 - accuracy: 0.9900 - val_loss: 0.0365 - val_accuracy: 0.8800\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9908 \n",
      "Epoch 00040: val_loss did not improve from 0.03029\n",
      "10/10 [==============================] - 553s 55s/step - loss: 0.0025 - accuracy: 0.9908 - val_loss: 0.0759 - val_accuracy: 0.7550\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9975     \n",
      "Epoch 00041: val_loss did not improve from 0.03029\n",
      "10/10 [==============================] - 552s 55s/step - loss: 0.0010 - accuracy: 0.9975 - val_loss: 0.0985 - val_accuracy: 0.7275\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 6.2715e-04 - accuracy: 0.9983 \n",
      "Epoch 00042: val_loss improved from 0.03029 to 0.02710, saving model to top_model.h5\n",
      "10/10 [==============================] - 555s 56s/step - loss: 6.2715e-04 - accuracy: 0.9983 - val_loss: 0.0271 - val_accuracy: 0.9025\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9950 \n",
      "Epoch 00043: val_loss improved from 0.02710 to 0.01111, saving model to top_model.h5\n",
      "10/10 [==============================] - 558s 56s/step - loss: 0.0015 - accuracy: 0.9950 - val_loss: 0.0111 - val_accuracy: 0.9575\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 7.7984e-04 - accuracy: 0.9975 \n",
      "Epoch 00044: val_loss did not improve from 0.01111\n",
      "10/10 [==============================] - 552s 55s/step - loss: 7.7984e-04 - accuracy: 0.9975 - val_loss: 0.0378 - val_accuracy: 0.8875\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 2.5565e-04 - accuracy: 1.0000 \n",
      "Epoch 00045: val_loss did not improve from 0.01111\n",
      "10/10 [==============================] - 553s 55s/step - loss: 2.5565e-04 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9550\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9942 \n",
      "Epoch 00046: val_loss did not improve from 0.01111\n",
      "10/10 [==============================] - 553s 55s/step - loss: 0.0015 - accuracy: 0.9942 - val_loss: 0.0240 - val_accuracy: 0.9075\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 8.3991e-04 - accuracy: 0.9975 \n",
      "Epoch 00047: val_loss did not improve from 0.01111\n",
      "10/10 [==============================] - 556s 56s/step - loss: 8.3991e-04 - accuracy: 0.9975 - val_loss: 0.1055 - val_accuracy: 0.7050\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9942  \n",
      "Epoch 00048: val_loss did not improve from 0.01111\n",
      "10/10 [==============================] - 887s 90s/step - loss: 0.0026 - accuracy: 0.9942 - val_loss: 0.1010 - val_accuracy: 0.6975\n",
      "Epoch 49/50\n",
      " 4/10 [===========>..................] - ETA: 7:03 - loss: 0.0030 - accuracy: 0.9922"
     ]
    }
   ],
   "source": [
    "model.fit(trainX, trainY,shuffle=True,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(testX, testY),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "QLtRqPzhLOUF",
    "outputId": "7de4cd06-136d-424b-dd2d-6d1d85487384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.16000358760356903\n",
      "Test accuracy: 0.22499999403953552\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(testX, testY, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9oDaZS8LuWem",
    "outputId": "c308968b-442f-49da-a69e-1a87bdb1cf27"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('top_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ltfB09zptlNN",
    "outputId": "e023e99b-eb5a-449a-e08f-b124b3f7f284",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.01113548781722784\n",
      "Test accuracy: 0.9574999809265137\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(testX, testY, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ov6w2Kmdv4dV"
   },
   "outputs": [],
   "source": [
    "def blur_img(pil_im):\n",
    "    #Adding Blur to image \n",
    "    blur_img = pil_im.filter(ImageFilter.GaussianBlur(radius=3)) # ouput\n",
    "    #imshow(blur_img)\n",
    "    blur_img=blur_img.resize((105,105))\n",
    "    return blur_img\n",
    "\n",
    "img_path=\"sample/roboto.jpg\"\n",
    "pil_im =PIL.Image.open(img_path).convert('L')\n",
    "pil_im=blur_img(pil_im)\n",
    "org_img = img_to_array(pil_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jN4su5FX3MzC"
   },
   "outputs": [],
   "source": [
    "def rev_conv_label(label):\n",
    "    print('{:.2f}% Lato'.format(label[0][0]*100))\n",
    "    print('{:.2f}% Raleway'.format(label[0][1]*100))\n",
    "    print('{:.2f}% Roboto'.format(label[0][2]*100))\n",
    "    print('{:.2f}% Sansation'.format(label[0][3]*100))\n",
    "    print('{:.2f}% Walkway'.format(label[0][4]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1yBSPTh0ooD"
   },
   "outputs": [],
   "source": [
    "data=[]\n",
    "data.append(org_img)\n",
    "data = np.asarray(data, dtype=\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JR2YCKaaznhT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.3906234e-06 1.0744799e-07 9.9999428e-01 1.1749842e-06 2.0106661e-06]]\n"
     ]
    }
   ],
   "source": [
    "y = model.predict(data)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "SQjS-Iv80iLc",
    "outputId": "75bc8aff-55d9-4675-bd36-96070ecfcf49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00% Lato\n",
      "0.00% Raleway\n",
      "100.00% Roboto\n",
      "0.00% Sansation\n",
      "0.00% Walkway\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label = rev_conv_label(y)\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(pil_im, interpolation='nearest', cmap=cm.gray)\n",
    "ax.text(5, 5, label , bbox={'facecolor': 'white', 'pad': 10})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Font_Detect_Updated v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
